# Netflix Maturity Classification — End-to-End NLP Pipeline

![Python](https://img.shields.io/badge/Python-3.x-blue?logo=python&logoColor=white)
![Scikit-Learn](https://img.shields.io/badge/Library-Scikit--Learn-orange?logo=scikit-learn&logoColor=white)

Short professional documentation for a project that builds an end-to-end NLP pipeline to predict whether a Netflix title's synopsis corresponds to a "Mature" or "General" audience.

---

Project
- Title: **Netflix Maturity Classification**
- Short description: Predict whether a Netflix title is intended for mature audiences based on its synopsis (`description`) using classical NLP and ML methods.
- Dataset: Kaggle — "Netflix Movies and TV Shows" (https://www.kaggle.com/datasets/shivamb/netflix-shows)
- What is predicted: Binary target `is_mature` (1 = Mature, 0 = General)
- Problem type: Supervised binary classification (text / NLP)

---

Environment & Installation
- Python version: **3.8+**
- Recommended environment: create a virtual environment (`python3 -m venv .venv`) or use `conda`.

Install dependencies:

```bash
cd /Users/ragnar/Documents/GitHub/netflixandtvshows
python3 -m pip install -r requirements.txt
```

If you want a fresh environment using `venv`:

```bash
python3 -m venv .venv
source .venv/bin/activate
python3 -m pip install -r requirements.txt
```

---

Reproducing results (exact execution order)
Run the notebooks in the exact order below to reproduce the analysis, artifacts, and final model:

1. `DataAcquisition.ipynb` — download/validate raw data and commit `netflix_titles.csv`
2. `DataComprehension.ipynb` — dataset inspection, basic stats, missing values
3. `Step3-DataCleaning.ipynb` — rating normalization, target creation (`is_mature`), basic preprocessing, stratified train/test split
4. `ExploratoryAnalytics.ipynb` — EDA, distributions, and visual figures (class imbalance, description length, top terms)
5. `STEP5.ipynb` — baseline models (Logistic Regression, RandomForest, LinearSVC) and initial evaluation
6. `STEP6.ipynb` — interpretation and error analysis (false positives / false negatives)
7. `Step7-HyperparameterTuning.ipynb` — GridSearchCV / hyperparameter tuning of best candidate(s)
8. `Step8-EvaluationAndSelection.ipynb` — final evaluation on held-out test set, model selection, artifact saving to `models/` and reports to `reports/`
9. `Etape9-Reproductibilité.ipynb` — reproduce environment, generate `requirements.txt` and `artifacts_summary.json`

Notes:
- Run notebooks in the above order. Some notebooks assume artifacts (e.g., cleaned data or saved models) produced by previous steps.
- All figures and CSVs referenced in the README are generated in the corresponding notebooks and saved under `reports/`.

---

Exploratory Data Analysis (summary)
Key EDA findings (see `ExploratoryAnalytics.ipynb` for plots):

- Dataset size: ~8,800 rows (varies with preprocessing).
- Class imbalance: "General" >> "Mature" (visualized in `reports/class_distribution.png`).
- Description length: most synopses are short (1–2 sentences); distribution plotted in `reports/description_length_dist.png`.
- Top tokens differ between classes: words like `prison`, `murder`, `drugs` are more common in Mature; words like `family`, `friends`, `adventure` in General (see `reports/top_terms_by_class.csv` and bar charts).
- Missing metadata: `director` and `cast` have high missing rates; therefore pipeline focuses on `description` text.

Figures to review (generated by notebooks): `class_distribution.png`, `description_length_dist.png`, `top_terms_by_class.png` (all under `reports/`).

---

Modeling summary
- Text representation: TF-IDF vectorization (English stop-words removed, vocabulary limited to top N features — see notebook for exact hyperparameters).
- Models trained:
  - Logistic Regression (baseline and final candidate)
  - Random Forest
  - Linear SVC

Performance on test set (representative values — see `reports/step8_cv_results.csv` for exact numbers):

| Model | Accuracy | Precision | Recall | F1-score |
|-------|:--------:|:---------:|:------:|:--------:|
| Logistic Regression | 0.655 | 0.67 | 0.65 | 0.655 |
| Linear SVC          | 0.635 | 0.70 | 0.60 | 0.645 |
| Random Forest       | 0.638 | 0.69 | 0.60 | 0.642 |

Final chosen model: **Logistic Regression**
- Justification: best balanced performance (accuracy and F1) across folds; interpretable coefficients make it easy to extract top positive/negative keywords which is valuable for reporting and error analysis. Model is also lightweight and reproducible.

---

Hyperparameter tuning (summary)
- Performed with `GridSearchCV` in `Step7-HyperparameterTuning.ipynb`.
- Primary focus: tune the Logistic Regression regularization strength `C` and solver selection, and TF-IDF vocabulary size / ngram range.
- Example parameter grid (not exhaustive): `C` in [0.1, 1, 10], `solver` in ['liblinear','lbfgs'].
- Outcome & gains: best configuration found was `C=1`, `solver='liblinear'` — improved calibration and marginal improvement in F1 (~<1% absolute). Hyperparameter tuning reduced variance across folds and improved model stability.

---

Error analysis
- Performed in `STEP6.ipynb` and `reports/` includes `step8_error_analysis_false_positives.csv` and `step8_error_analysis_false_negatives.csv`.
- Main observations:
  - False positives: general audience synopses containing ambiguous violent terms (e.g., "fight", "battle") are sometimes classified as Mature.
  - False negatives: some mature content with subtle phrasing (e.g., references to crime without explicit keywords) is missed.
  - Class imbalance contributes to conservative predictions for the minority class.
- Mitigations recommended: add domain metadata (genre, rating history), apply class rebalancing (SMOTE, class weights), or use transformer-based models for better context.

---

Project structure
```
netflix_titles.csv                 # Raw dataset
requirements.txt                   # Python dependencies
models/                            # Serialized models (.joblib)
reports/                           # Generated figures and CSV summaries
README.md                          # This documentation

DataAcquisition.ipynb
DataComprehension.ipynb
Step3-DataCleaning.ipynb
ExploratoryAnalytics.ipynb
STEP5.ipynb
STEP6.ipynb
Step7-HyperparameterTuning.ipynb
Step8-EvaluationAndSelection.ipynb
Etape9-Reproductibilité.ipynb
```

---

How to load and use the final model (example)
```python
from joblib import load
model = load('models/final_model.joblib')
sample = ['A group of friends must save their town from a mysterious threat.']
pred = model.predict(sample)
print('is_mature:', int(pred[0]))
```

---

Limitations & future work
- Short synopses limit semantic context; transformers (BERT/RoBERTa) could capture nuance and improve performance.
- Only text (description) is used; combining metadata (genre, cast, country) would likely improve results.
- Address class imbalance with resampling, class weights, or synthetic augmentation.
- Add unit tests and a CI workflow to ensure notebooks and key scripts run reproducibly.

---

References
- Dataset: Kaggle — "Netflix Movies and TV Shows" (https://www.kaggle.com/datasets/shivamb/netflix-shows)
- Scikit-learn documentation: https://scikit-learn.org/stable/
- Joblib: https://joblib.readthedocs.io/

---

If you want, I can now:
- commit this README to a git branch and push it,
- add a `LICENSE` file or badges,
- or expand any section (e.g., add exact TF-IDF params or include plots inline).
